# Chatbot RAG com Gemini e Node.js

Este projeto implementa um chatbot avanÃ§ado utilizando a arquitetura RAG (Retrieval-Augmented Generation). Ele permite que os usuÃ¡rios "conversem" com uma coleÃ§Ã£o de documentos PDF, obtendo respostas precisas e contextuais baseadas exclusivamente no conteÃºdo dos arquivos fornecidos. A aplicaÃ§Ã£o Ã© construÃ­da com Node.js para o backend e HTML/CSS/JS puro para o frontend, utilizando os modelos de IA da Google (Gemini) e o banco de dados vetorial Pinecone.

## âœ¨ Funcionalidades

- **Interface de Chat Intuitiva**: Uma interface de chat limpa e responsiva para interagir com o assistente.
- **Upload de Documentos**: Uma pÃ¡gina de administraÃ§Ã£o (`/admin.html`) para fazer o upload de um ou mais arquivos PDF, que servirÃ£o como base de conhecimento.
- **Processamento Automatizado (IngestÃ£o)**: Os PDFs enviados sÃ£o automaticamente processados: o texto Ã© extraÃ­do, dividido em blocos (chunks), vetorizado com a API Gemini e armazenado no Pinecone.
- **Monitoramento em Tempo Real**: A pÃ¡gina de administraÃ§Ã£o exibe logs em tempo real do processo de ingestÃ£o dos documentos.
- **Respostas por Streaming**: As respostas do chatbot sÃ£o transmitidas palavra por palavra, melhorando a experiÃªncia do usuÃ¡rio.
- **HistÃ³rico de Conversa**: O chatbot considera o histÃ³rico da conversa para responder a perguntas de acompanhamento de forma mais eficaz.
- **ExibiÃ§Ã£o de Fontes**: Para cada resposta, o chatbot pode mostrar os trechos exatos dos documentos originais que foram usados para formulÃ¡-la.

## ğŸš€ Arquitetura e Funcionamento

O projeto Ã© dividido em dois processos principais: **IngestÃ£o** e **Chat (RAG)**.

### 1. Processo de IngestÃ£o de Documentos

1.  **Upload**: O administrador acessa a pÃ¡gina `/admin.html` e faz o upload dos arquivos PDF.
2.  **Recebimento**: O servidor Express (usando `multer`) recebe os arquivos em memÃ³ria.
3.  **ExtraÃ§Ã£o de Texto**: O texto de cada PDF Ã© extraÃ­do usando a biblioteca `pdf-parse`.
4.  **FragmentaÃ§Ã£o (Chunking)**: O texto extraÃ­do Ã© dividido em fragmentos menores e sobrepostos (`chunks`) usando `@langchain/textsplitters` para garantir a coesÃ£o semÃ¢ntica.
5.  **GeraÃ§Ã£o de Embeddings**: Cada `chunk` de texto Ã© enviado para o modelo de embedding da Google (`text-embedding-004`) para ser convertido em um vetor numÃ©rico que representa seu significado.
6.  **Armazenamento Vetorial**: Os `chunks` de texto e seus respectivos vetores (embeddings) sÃ£o armazenados (upsert) em um Ã­ndice no **Pinecone**.

### 2. Processo de Chat (Retrieval-Augmented Generation)

1.  **Pergunta do UsuÃ¡rio**: O usuÃ¡rio envia uma pergunta atravÃ©s da interface de chat.
2.  **TransformaÃ§Ã£o da Pergunta**: A pergunta Ã© combinada com o histÃ³rico da conversa para criar uma "pergunta autÃ´noma", que Ã© mais clara para a busca semÃ¢ntica.
3.  **VetorizaÃ§Ã£o da Pergunta**: A pergunta (transformada) Ã© convertida em um vetor usando o mesmo modelo de embedding da Google.
4.  **Busca por Similaridade (Retrieval)**: O vetor da pergunta Ã© usado para consultar o Ã­ndice **Pinecone**, que retorna os `chunks` de texto mais relevantes (semanticamente similares).
5.  **Aumento do Prompt (Augmentation)**: Um prompt detalhado Ã© montado, contendo:
    - O contexto (os `chunks` relevantes recuperados do Pinecone).
    - O histÃ³rico da conversa.
    - A pergunta original do usuÃ¡rio.
    - InstruÃ§Ãµes para o modelo se basear *exclusivamente* no contexto fornecido.
6.  **GeraÃ§Ã£o da Resposta (Generation)**: O prompt aumentado Ã© enviado para o modelo de chat da Google (`gemini-2.5-flash`), que gera uma resposta coerente e baseada nos fatos apresentados.
7.  **Streaming**: A resposta Ã© enviada de volta para o frontend em tempo real.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Backend**: Node.js, Express.js
- **Frontend**: HTML5, Tailwind CSS, JavaScript (Vanilla)
- **InteligÃªncia Artificial**:
    - **Google Gemini**:
        - `gemini-2.5-flash`: Para geraÃ§Ã£o de respostas no chat.
        - `text-embedding-004`: Para criaÃ§Ã£o de embeddings de texto.
- **Banco de Dados Vetorial**: Pinecone
- **Processamento de Arquivos**:
    - `multer`: Para upload de arquivos.
    - `pdf-parse`: Para extraÃ§Ã£o de texto de PDFs.
    - `@langchain/textsplitters`: Para fragmentaÃ§Ã£o de texto.

## ğŸ“‚ Estrutura do Projeto

```
/
â”œâ”€â”€ chat-api-service/
â”‚   â”œâ”€â”€ public/             # Arquivos do frontend (HTML, CSS, JS)
â”‚   â”‚   â”œâ”€â”€ admin.html
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ js/
â”‚   â”‚       â”œâ”€â”€ admin.js
â”‚   â”‚       â””â”€â”€ script.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/         # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”‚   â”‚   â”œâ”€â”€ controllers/    # Controladores (chat, upload)
â”‚   â”‚   â”œâ”€â”€ routes/         # DefiniÃ§Ã£o das rotas da API
â”‚   â”‚   â””â”€â”€ services/       # LÃ³gica de negÃ³cio (ingestÃ£o, RAG)
â”‚   â”œâ”€â”€ .env.example        # Exemplo de arquivo de ambiente
â”‚   â”œâ”€â”€ index.js            # Ponto de entrada do servidor
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ .gitignore
```

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos
- Node.js (v18 ou superior)
- Acesso Ã s APIs do Google Gemini e Pinecone.

### Passos

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone <URL_DO_SEU_REPOSITORIO>
    cd chatbot-rag-node
    ```

2.  **Navegue atÃ© o serviÃ§o da API:**
    ```bash
    cd chat-api-service
    ```

3.  **Instale as dependÃªncias:**
    ```bash
    npm install
    ```

4.  **Configure as variÃ¡veis de ambiente:**
    - Renomeie o arquivo `.env.example` (se houver) para `.env` ou crie um novo.
    - Preencha as seguintes variÃ¡veis no arquivo `.env`:
    ```env
    # Chave de API do Google Gemini
    GEMINI_API_KEY="SUA_CHAVE_AQUI"

    # Chave de API do Pinecone
    PINECONE_API_KEY="SUA_CHAVE_AQUI"

    # Host do seu Ã­ndice Pinecone (encontrado no dashboard do Pinecone)
    PINECONE_HOST="URL_DO_SEU_INDICE.pinecone.io"
    ```

5.  **Inicie o servidor:**
    ```bash
    node index.js
    ```

6.  **Acesse a aplicaÃ§Ã£o:**
    - **Chat**: Abra o navegador e acesse `http://localhost:8080`
    - **Admin (Upload)**: Acesse `http://localhost:8080/admin.html`

## ğŸš€ Como Usar

1.  Primeiro, vÃ¡ para a **pÃ¡gina de administraÃ§Ã£o** para carregar os documentos que servirÃ£o de base de conhecimento.
2.  Selecione um ou mais arquivos PDF e clique em "Enviar e Processar Arquivos".
3.  Aguarde o processo de ingestÃ£o terminar (vocÃª pode acompanhar os logs na tela).
4.  ApÃ³s a conclusÃ£o, vÃ¡ para a **pÃ¡gina de chat** e comece a fazer perguntas!
